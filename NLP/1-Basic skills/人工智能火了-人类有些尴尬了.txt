被沙特授予公民身份的机器人索菲亚和它的创造者大卫·汉森索菲亚不是人，她只是个很聪明的机器人；索菲亚又是“人”，不久前，她被沙特授予公民身份，加入人类籍。

索菲亚很友好，与人谈笑自如，甚至还会眼神交流，并在MV里与歌星王力宏“结了婚”；索菲亚又很“恐怖”，声称未来目标是想去上学，成立家庭，并——毁灭人类。

无论这句话是调侃还是隐喻，设计出她的人类，尴尬了。

在近日召开的“人工智能的技术、伦理与法律的关键科学问题”的香山科学会议上，中科院科技战略咨询研究院研究员李真真举索菲亚的例子，是想提出一个问题：在技术高歌猛进的同时，人工智能不断模糊着物理世界和个人的界限，不断刷新人的认知和社会关系，延伸出复杂的伦理、法律和安全问题，但相应的规范和制度设计还存在盲区，这是一个极大的挑战。

“我国的人工智能技术可谓与世界发达国家‘同步’，但伦理和法律研究则严重滞后，这种‘缺位’会制约我们未来的发展。”李真真说。

为构建一个人工智能健康发展的伦理和法律环境，来自自然科学、人文社会科学领域的专家学者和产业界人士聚集在一起，尝试跨越学科的鸿沟，寻找共同的交集，研讨人工智能最基本的问题。

人工智能很牛吗？ 牛，但也有可能犯大错

人工智能火了！人工智能牛了！很大程度归功于近年来一只不断进化的“狗”——阿尔法狗（AlphaGo）。

中科院院士张钹简单分析了人工智能发展的两条路径：一是符号主义，即从信息处理的宏观层面去模拟智能；二是连接主义，即从网络介观层面去模拟人类行为。当人工智能的开拓者提出上述方向时，不少人认为不可能，但事实证明这两条路都行得通。

“人工智能第一次震撼，是IBM的‘深蓝’程序打赢国际象棋冠军，这是用计算机模拟人类下象棋的理性思考过程，证明了符号主义这一条路走得通。”张钹说。

人工智能第二次对人类的“暴击”，是基于神经网络的深度学习，AlphaGo抛弃了传统围棋程序的编程方法，创造性地利用机器学习，来获取下棋的经验与直觉，结果战胜世界围棋冠军。“更值得注意的是AlphaGo Zero从零开始，通过36小时自我学习，超越人类3000年的围棋经验，以100比0击败了上一版本的AlphaGo。这证明第二条路也走得通。”张钹说。

“这让人欢欣鼓舞，也令人担忧。”张钹的“忧”，指的是基于深度学习的人工智能系统存在的根本性缺陷——不可解释和不可理解，就事论事，缺乏推广能力，遇到新的情况一筹莫展等。因此当面对动态变化的环境，信息不完全、存在干扰与虚假信息时，人工智能系统性能就会显著下降。

“当前的人工智能与人类智能本质上是不同的。”张钹说，与人类相比，人工智能系统抗干扰能力（鲁棒性）差，推广能力弱，甚至可能犯大错。“基于深度学习的模式识别系统尽管可以准确地区分不同事物，但本质上不认识它们。与人类不一样，它不会举一反三，更不会‘知其所以然’。使用这样的人工智能系统需要十分小心。”

“现在大家对人工智能有无限期待。围棋有规则，现实生活中没有规则。人工智能产品完成单项任务很牛，但遇到复杂情况，实际没那么厉害。”海尔公司CTO赵峰认为。

人工智能可怕吗？ 远虑尚“远”，近忧在即

人工智能会威胁人类吗？马斯克、霍金、扎克伯格……科技和产业界的大腕对此的争论和互怼一直没有停歇。

参加香山科学会议的科学家认为，人工智能威胁论拥趸者所指的“强人工智能”到来还比较远，现在发展的多是擅长完成单项任务的“弱人工智能”。“人工智能还在生长发展过程中，是否造成威胁估计是下一代科学家面临的问题，我们现在的任务是把它‘养大’。”不过，中科院院士何积丰也坦承，现在人工智能也有“内忧外患”，如无人机黑飞乱飞管理乱象，恐怖主义黑客攻击等。

“世界上没有免费的午餐，机器通过‘黑箱’学习（深度学习）方法取得的智能，由于与人类认知行为存在根本差异，因此也将带来潜在的风险。”张钹说，人工智能全面超越人类智能并出现自我意识，是危险的，不过这是远虑；但其不可解释性会带来“近忧”，如将深度学习应用于军事决策，万一系统出现原则性决策失误怎么办？

人类准备好了吗？ 远远没有，急需跟进

“人类现有的概念框架及知识储备难以应对人工智能带来的影响，也使我们不得不面对‘制度性风险’。”李真真说，人工智能技术的社会应用迅速改变了人类的生存环境，重塑人的行为，也不断挑战诸如隐私、责任等概念内涵及其既有策略。

李真真以“隐私”举例说，传统法律上，隐私是一种权利的概念，但现在它还可以是一种商品，即我们让出一部分个人的隐私或信息以换取服务和产品，这就需要法律的及时跟进。再有，匿名化技术的发展为隐私保护提供了新的工具，但如果对于匿名化数据的法律概念和认定标准上没有明确规定，很可能会导致数据的滥用。同时，隐私保护与国家安全、商业利益如何平衡，也是问题。再比如“责任”，比较典型的就是自动驾驶系统的责任认定。“还有人工智能的预测或决策，如预测犯罪，这将使我们面对一个更为复杂的法律问题。”

“法律具有滞后性，这就要求我们不断地根据出现的新情况和新的社会难题，对人工智能带来的影响进行伦理评估，以保障相关法律和政策的及时跟进。”李真真说。

人机可以和谐共处吗？ 嵌入伦理法律框架是最大的科学挑战

人工智能是否会产生歧视？答案是肯定的，这可以体现在数据选择和算法上。

有科学家研究，通过使用机器学习算法帮助银行提供接受还是拒绝房贷的建议，无论如何，在审查神经网络决策制定流程的结果时，发现黑人申请的批准率大大低于白人申请的批准率。

这就是人工智能工具存在的“黑箱”般的不透明性。

“人机关系中，智能机器与人类的价值观和规范体系必须一致。”李真真说，如何将人类的价值观和规范嵌入人工智能系统，赋予AI以人性的光辉，成为当前所面临最现实的挑战。

前有科幻小说家阿西莫夫著名的机器人学三大定律，近年来，国际人工智能界日益重视人工智能中的伦理与法律问题，并推动相关技术标准及社会规范的研讨和制定，如IEEE全球人工智能与伦理倡议、阿西洛马人工智能23条伦理原则，我国的《新一代人工智能发展规划》也专门提出人工智能伦理与法律的三步走规划。“但是，将伦理与法律要求嵌入到AI系统，仍是全世界前沿性的科学难题，这需要技术、伦理、法律等控制手段配合使用、高度融合和跨学科合作。”李真真说。

“智能机器不是代替人，而是要协助人做好工作。人和机器各有优势，要互相了解才能实现人机协作，但人还是人机关系的主导者。依照这种思想，才可能将人工智能引向人机合作的发展道路。”张钹说。